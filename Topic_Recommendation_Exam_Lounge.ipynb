{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Recommendation_Exam Lounge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdkmJH3MVXZpFkMCgMtOfK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkal1234/Topic-Recommendation-System_E-learning-Platform/blob/main/Topic_Recommendation_Exam_Lounge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5akF-jS2iIC"
      },
      "source": [
        "\n",
        "A Collaborative Filtering Approach Towards Implementation of Topic Recommendation System for an E-Learning Platform ExamLounge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUjiFx5vo3cB"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"../../\")\n",
        "import os\n",
        "!{sys.executable} -m pip install surprise\n",
        "!{sys.executable} -m pip install papermill \n",
        "import papermill as pm\n",
        "!{sys.executable} -m pip install scrapbook\n",
        "import scrapbook as sb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import re\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xauSj0pNYfWp"
      },
      "source": [
        "We will use the ExamLounge dataset, which is composed of integer user level ratings from 1 to 5.\n",
        "\n",
        "**Dataset:** We have 2 Dataset csv files named as topics.csv and level_ratings.csv\n",
        "\n",
        "**\"ExamLounge_Topics.csv\":** It contains 3 Columns named as topicId, topic_title and exam &\n",
        "45,756 Rows. \n",
        "\n",
        "**\"LevelRatings.csv\":** It contains 4 Columns named as userId,  topicId, rating, timestamp & 15,323 Rows. \n",
        "\n",
        "PS: The Data is taken from the Exam Lounge: Ed.Tech Startup in this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvZBex-OYNgG"
      },
      "source": [
        "class ExamLounge:\n",
        "    topicId_to_name = {}\n",
        "    name_to_topicId = {}\n",
        "    ratingsPath = '/content/LevelRatings.csv'\n",
        "    topicsPath = '/content/ExamLounge_Topics.csv'\n",
        "    \n",
        "    def loadExamLoungeLatestSmall(self):\n",
        "\n",
        "        # Look for files relative to the directory we are running from\n",
        "        os.chdir(os.path.dirname(sys.argv[0]))\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.topicId_to_name = {}\n",
        "        self.name_to_topicId = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.topicsPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "                topicReader = csv.reader(csvfile)\n",
        "                next(topicReader)  #Skip header line\n",
        "                for row in topicReader:\n",
        "                    topicId = int(row[0])\n",
        "                    topicName = row[1]\n",
        "                    self.topicId_to_name[topicId] = topicName\n",
        "                    self.name_to_topicId[topicName] = topicId\n",
        "\n",
        "        return ratingsDataset\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    topicId = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((topicId, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                topicId = int(row[1])\n",
        "                ratings[topicId] += 1\n",
        "        rank = 1\n",
        "        for topicId, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[topicId] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "    \n",
        "    def getexam(self):\n",
        "        exam = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.topicsPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            topicReader = csv.reader(csvfile)\n",
        "            next(topicReader)  #Skip header line\n",
        "            for row in topicReader:\n",
        "                topicId = int(row[0])\n",
        "                genreList = row[2].split('|')\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                exam[topicId] = genreIDList\n",
        "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
        "        for (topicId, genreIDList) in exam.items():\n",
        "            bitfield = [0] * maxGenreID\n",
        "            for genreID in genreIDList:\n",
        "                bitfield[genreID] = 1\n",
        "            exam[topicId] = bitfield            \n",
        "        \n",
        "        return exam\n",
        "    \n",
        "    def getYears(self):\n",
        "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
        "        years = defaultdict(int)\n",
        "        with open(self.topicsPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            topicReader = csv.reader(csvfile)\n",
        "            next(topicReader)\n",
        "            for row in topicReader:\n",
        "                topicId = int(row[0])\n",
        "                topic_title = row[1]\n",
        "                m = p.search(topic_title)\n",
        "                year = m.group(1)\n",
        "                if year:\n",
        "                    years[topicId] = int(year)\n",
        "        return years\n",
        "    \n",
        "    def getMiseEnScene(self):\n",
        "        mes = defaultdict(list)\n",
        "        with open(\"LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
        "            mesReader = csv.reader(csvfile)\n",
        "            next(mesReader)\n",
        "            for row in mesReader:\n",
        "                topicId = int(row[0])\n",
        "                avgShotLength = float(row[1])\n",
        "                meanColorVariance = float(row[2])\n",
        "                stddevColorVariance = float(row[3])\n",
        "                meanMotion = float(row[4])\n",
        "                stddevMotion = float(row[5])\n",
        "                meanLightingKey = float(row[6])\n",
        "                numShots = float(row[7])\n",
        "                mes[topicId] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
        "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
        "        return mes\n",
        "    \n",
        "    def gettopicName(self, topicId):\n",
        "        if topicId in self.topicId_to_name:\n",
        "            return self.topicId_to_name[topicId]\n",
        "        else:\n",
        "            return \"\"\n",
        "        \n",
        "    def gettopicId(self, topicName):\n",
        "        if topicName in self.name_to_topicId:\n",
        "            return self.name_to_topicId[topicName]\n",
        "        else:\n",
        "            return 0    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYAO2jwebAeI"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from surprise import accuracy\n",
        "from collections import defaultdict\n",
        "\n",
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def GetTopN(predictions, n=10, minimumRating=4.0):\n",
        "        topN = defaultdict(list)\n",
        "\n",
        "\n",
        "        for userID, topicId, actualRating, estimatedRating, _ in predictions:\n",
        "            if (estimatedRating >= minimumRating):\n",
        "                topN[int(userID)].append((int(topicId), estimatedRating))\n",
        "\n",
        "        for userID, ratings in topN.items():\n",
        "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            topN[int(userID)] = ratings[:n]\n",
        "\n",
        "        return topN\n",
        "\n",
        "    def HitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for leftOut in leftOutPredictions:\n",
        "            userID = leftOut[0]\n",
        "            leftOuttopicId = leftOut[1]\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for topicId, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOuttopicId) == int(topicId)):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOuttopicId, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Only look at ability to recommend things the users actually liked...\n",
        "            if (actualRating >= ratingCutoff):\n",
        "                # Is it in the predicted top 10 for this user?\n",
        "                hit = False\n",
        "                for topicId, predictedRating in topNPredicted[int(userID)]:\n",
        "                    if (int(leftOuttopicId) == topicId):\n",
        "                        hit = True\n",
        "                        break\n",
        "                if (hit) :\n",
        "                    hits += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def RatingHitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = defaultdict(float)\n",
        "        total = defaultdict(float)\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOuttopicId, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hit = False\n",
        "            for topicId, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOuttopicId) == topicId):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits[actualRating] += 1\n",
        "\n",
        "            total[actualRating] += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        for rating in sorted(hits.keys()):\n",
        "            print (rating, hits[rating] / total[rating])\n",
        "\n",
        "    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
        "        summation = 0\n",
        "        total = 0\n",
        "        # For each left-out rating\n",
        "        for userID, leftOuttopicId, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hitRank = 0\n",
        "            rank = 0\n",
        "            for topicId, predictedRating in topNPredicted[int(userID)]:\n",
        "                rank = rank + 1\n",
        "                if (int(leftOuttopicId) == topicId):\n",
        "                    hitRank = rank\n",
        "                    break\n",
        "            if (hitRank > 0) :\n",
        "                summation += 1.0 / hitRank\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        return summation / total\n",
        "\n",
        "    # What percentage of users have at least one \"good\" recommendation\n",
        "    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
        "        hits = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            hit = False\n",
        "            for topicId, predictedRating in topNPredicted[userID]:\n",
        "                if (predictedRating >= ratingThreshold):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit):\n",
        "                hits += 1\n",
        "\n",
        "        return hits / numUsers\n",
        "\n",
        "    def Diversity(topNPredicted, simsAlgo):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        simsMatrix = simsAlgo.compute_similarities()\n",
        "        for userID in topNPredicted.keys():\n",
        "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "            for pair in pairs:\n",
        "                topic1 = pair[0][0]\n",
        "                topic2 = pair[1][0]\n",
        "                innerID1 = simsAlgo.trainset.to_inner_iid(str(topic1))\n",
        "                innerID2 = simsAlgo.trainset.to_inner_iid(str(topic2))\n",
        "                similarity = simsMatrix[innerID1][innerID2]\n",
        "                total += similarity\n",
        "                n += 1\n",
        "\n",
        "        S = total / n\n",
        "        return (1-S)\n",
        "\n",
        "    def Novelty(topNPredicted, rankings):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            for rating in topNPredicted[userID]:\n",
        "                topicId = rating[0]\n",
        "                rank = rankings[topicId]\n",
        "                total += rank\n",
        "                n += 1\n",
        "        return total / n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8UU1BYqbzbt"
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from surprise import KNNBaseline\n",
        "\n",
        "\n",
        "class EvaluationData:\n",
        "    \n",
        "    def __init__(self, data, popularityRankings):\n",
        "        \n",
        "        self.rankings = popularityRankings\n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "        \n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "        \n",
        "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        #And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "            \n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "        \n",
        "        #Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "            \n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "    \n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "    \n",
        "    def GetAntiTestSetForUser(self, testSubject):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(testSubject))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                                 i in trainset.all_items() if\n",
        "                                 i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "    \n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "    \n",
        "    def GetLOOCVTrainSet(self):\n",
        "        return self.LOOCVTrain\n",
        "    \n",
        "    def GetLOOCVTestSet(self):\n",
        "        return self.LOOCVTest\n",
        "    \n",
        "    def GetLOOCVAntiTestSet(self):\n",
        "        return self.LOOCVAntiTestSet\n",
        "    \n",
        "    def GetSimilarities(self):\n",
        "        return self.simsAlgo\n",
        "    \n",
        "    def GetPopularityRankings(self):\n",
        "        return self.rankings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T48DolOy1e73"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgguhS1G7Oxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7d6a96-0809-4197-e27e-e02e53bb3369"
      },
      "source": [
        "# %run ./ExamLounge.ipynb\n",
        "from surprise import KNNBasic\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "# %run ./RecommenderMetrics.ipynb\n",
        "# %run ./EvaluationData.ipynb\n",
        "\n",
        "def LoadExamLoungeData():\n",
        "    ml = ExamLounge()\n",
        "    print(\"Loading topic ratings...\")\n",
        "    data = ml.loadExamLoungeLatestSmall()\n",
        "    print(\"\\nComputing topic popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "ml, data, rankings = LoadExamLoungeData()\n",
        "\n",
        "evalData = EvaluationData(data, rankings)\n",
        "\n",
        "# Train on leave-One-Out train set\n",
        "trainSet = evalData.GetLOOCVTrainSet()\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': True\n",
        "               }\n",
        "\n",
        "model = KNNBasic(sim_options=sim_options)\n",
        "model.fit(trainSet)\n",
        "simsMatrix = model.compute_similarities()\n",
        "\n",
        "leftOutTestSet = evalData.GetLOOCVTestSet()\n",
        "\n",
        "# Build up dict to lists of (int(topicId), predictedrating) pairs\n",
        "topN = defaultdict(list)\n",
        "k = 10\n",
        "for uiid in range(trainSet.n_users):\n",
        "    # Get top N similar users to this one\n",
        "    similarityRow = simsMatrix[uiid]\n",
        "    \n",
        "    similarUsers = []\n",
        "    for innerID, score in enumerate(similarityRow):\n",
        "        if (innerID != uiid):\n",
        "            similarUsers.append( (innerID, score) )\n",
        "    \n",
        "    kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])\n",
        "    \n",
        "    # Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
        "    candidates = defaultdict(float)\n",
        "    for similarUser in kNeighbors:\n",
        "        innerID = similarUser[0]\n",
        "        userSimilarityScore = similarUser[1]\n",
        "        theirRatings = trainSet.ur[innerID]\n",
        "        for rating in theirRatings:\n",
        "            candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
        "        \n",
        "    # Build a dictionary of stuff the user has already seen\n",
        "    watched = {}\n",
        "    for itemID, rating in trainSet.ur[uiid]:\n",
        "        watched[itemID] = 1\n",
        "        \n",
        "    # Get top-rated items from similar users:\n",
        "    pos = 0\n",
        "    for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
        "        if not itemID in watched:\n",
        "            topicId = trainSet.to_raw_iid(itemID)\n",
        "            topN[int(trainSet.to_raw_uid(uiid))].append( (int(topicId), 0.0) )\n",
        "            pos += 1\n",
        "            if (pos > 40):\n",
        "                break\n",
        "    \n",
        "# Measure\n",
        "print(\"HR\", RecommenderMetrics.HitRate(topN, leftOutTestSet))   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "HR 0.05514157973174367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7PL5XTg7O95"
      },
      "source": [
        "#!pip install RecommenderMetrics\n",
        "#!pip install EvaluationData\n",
        "\n",
        "class EvaluatedAlgorithm:\n",
        "    \n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "        \n",
        "    def Evaluate(self, evaluationData, doTopN, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
        "        \n",
        "        if (doTopN):\n",
        "            # Evaluate top-10 with Leave One Out testing\n",
        "            if (verbose):\n",
        "                print(\"Evaluating top-N with leave-one-out...\")\n",
        "            self.algorithm.fit(evaluationData.GetLOOCVTrainSet())\n",
        "            leftOutPredictions = self.algorithm.test(evaluationData.GetLOOCVTestSet())        \n",
        "            # Build predictions for all ratings not in the training set\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetLOOCVAntiTestSet())\n",
        "            # Compute top 10 recs for each user\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Computing hit-rate and rank metrics...\")\n",
        "            # See how often we recommended a topic the user actually rated\n",
        "            metrics[\"HR\"] = RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions)   \n",
        "            # See how often we recommended a topic the user actually liked\n",
        "            metrics[\"cHR\"] = RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions)\n",
        "            # Compute ARHR\n",
        "            metrics[\"ARHR\"] = RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
        "        \n",
        "            #Evaluate properties of recommendations on full training set\n",
        "            if (verbose):\n",
        "                print(\"Computing recommendations with full data set...\")\n",
        "            self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetFullAntiTestSet())\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
        "            # Print user coverage with a minimum predicted rating of 4.0:\n",
        "            metrics[\"Coverage\"] = RecommenderMetrics.UserCoverage(  topNPredicted, \n",
        "                                                                   evaluationData.GetFullTrainSet().n_users, \n",
        "                                                                   ratingThreshold=4.0)\n",
        "            # Measure diversity of recommendations:\n",
        "            metrics[\"Diversity\"] = RecommenderMetrics.Diversity(topNPredicted, evaluationData.GetSimilarities())\n",
        "            \n",
        "            # Measure novelty (average popularity rank of recommendations):\n",
        "            metrics[\"Novelty\"] = RecommenderMetrics.Novelty(topNPredicted, \n",
        "                                                            evaluationData.GetPopularityRankings())\n",
        "        \n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "    \n",
        "        return metrics\n",
        "    \n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "    \n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53g39HD7PDc"
      },
      "source": [
        "#!pip install EvaluationData\n",
        "#!pip install EvaluatedAlgorithm\n",
        "\n",
        "class Evaluator:\n",
        "    \n",
        "    algorithms = []\n",
        "    \n",
        "    def __init__(self, dataset, rankings):\n",
        "        ed = EvaluationData(dataset, rankings)\n",
        "        self.dataset = ed\n",
        "        \n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "        \n",
        "    def Evaluate(self, doTopN):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        if (doTopN):\n",
        "            print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "                    \"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"cHR\", \"ARHR\", \"Coverage\", \"Diversity\", \"Novelty\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "                        name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"cHR\"], metrics[\"ARHR\"],\n",
        "                                      metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
        "        else:\n",
        "            print(\"{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"]))\n",
        "                \n",
        "        print(\"\\nLegend:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        if (doTopN):\n",
        "            print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
        "            print(\"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
        "            print(\"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\" )\n",
        "            print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "            print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "            print(\"           for a given user. Higher means more diverse.\")\n",
        "            print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")\n",
        "        \n",
        "    def SampleTopNRecs(self, ml, testSubject=85, k=10):\n",
        "        \n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.GetName())\n",
        "            \n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.GetFullTrainSet()\n",
        "            algo.GetAlgorithm().fit(trainSet)\n",
        "            \n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.GetAntiTestSetForUser(testSubject)\n",
        "        \n",
        "            predictions = algo.GetAlgorithm().test(testSet)\n",
        "            \n",
        "            recommendations = []\n",
        "            \n",
        "            print (\"\\nWe recommend:\")\n",
        "            for userID, topicId, actualRating, estimatedRating, _ in predictions:\n",
        "                inttopicId = int(topicId)\n",
        "                recommendations.append((inttopicId, estimatedRating))\n",
        "            \n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "            \n",
        "            for ratings in recommendations[:10]:\n",
        "                print(ml.gettopicName(ratings[0]), ratings[1])\n",
        "                \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNjiQjqw7PGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880dda69-cdd5-4f06-fbd9-cce6b00cc72b"
      },
      "source": [
        "#!pip install ExamLounge\n",
        "from surprise import KNNBasic\n",
        "from surprise import NormalPredictor\n",
        "#!pip install Evaluator\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadExamLoungeData():\n",
        "    ml = ExamLounge()\n",
        "    print(\"Loading topic ratings...\")\n",
        "    data = ml.loadExamLoungeLatestSmall()\n",
        "    print(\"\\nComputing topic popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadExamLoungeData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "# User-based KNN\n",
        "UserKNN = KNNBasic(sim_options = {'name': 'cosine', 'user_based': True})\n",
        "evaluator.AddAlgorithm(UserKNN, \"User KNN\")\n",
        "\n",
        "# Item-based KNN\n",
        "ItemKNN = KNNBasic(sim_options = {'name': 'cosine', 'user_based': False})\n",
        "evaluator.AddAlgorithm(ItemKNN, \"Item KNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "# Fight!\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  User KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Item KNN ...\n",
            "Evaluating accuracy...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "User KNN   0.9961     0.7711    \n",
            "Item KNN   0.9995     0.7798    \n",
            "Random     1.4385     1.1478    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  User KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "One Magic Christmas (1985) 5\n",
            "Step Into Liquid (2002) 5\n",
            "Art of War, The (2000) 5\n",
            "Taste of Cherry (Ta'm e guilass) (1997) 5\n",
            "King Is Alive, The (2000) 5\n",
            "Innocence (2000) 5\n",
            "MaelstrÃ¶m (2000) 5\n",
            "Faust (1926) 5\n",
            "Seconds (1966) 5\n",
            "Amazing Grace (2006) 5\n",
            "\n",
            "Using recommender  Item KNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Life in a Day (2011) 5\n",
            "Under Suspicion (2000) 5\n",
            "Asterix and the Gauls (AstÃ©rix le Gaulois) (1967) 5\n",
            "Find Me Guilty (2006) 5\n",
            "Elementary Particles, The (Elementarteilchen) (2006) 5\n",
            "Asterix and the Vikings (AstÃ©rix et les Vikings) (2006) 5\n",
            "From the Sky Down (2011) 5\n",
            "Vive L'Amour (Ai qing wan sui) (1994) 5\n",
            "Vagabond (Sans toit ni loi) (1985) 5\n",
            "Ariel (1988) 5\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Sleepers (1996) 5\n",
            "Beavis and Butt-Head Do America (1996) 5\n",
            "Fear and Loathing in Las Vegas (1998) 5\n",
            "Happiness (1998) 5\n",
            "Summer of Sam (1999) 5\n",
            "Bowling for Columbine (2002) 5\n",
            "Babe (1995) 5\n",
            "Birdcage, The (1996) 5\n",
            "Carlito's Way (1993) 5\n",
            "Wizard of Oz, The (1939) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQkte7nD7PIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9735d8b2-12b3-46ba-e279-54eafa9e4997"
      },
      "source": [
        "#from ExamLounge import ExamLounge\n",
        "from surprise import KNNBasic\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "        \n",
        "testSubject = '85'\n",
        "k = 10\n",
        "\n",
        "ml = ExamLounge()\n",
        "data = ml.loadExamLoungeLatestSmall()\n",
        "\n",
        "trainSet = data.build_full_trainset()\n",
        "\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': False\n",
        "               }\n",
        "\n",
        "model = KNNBasic(sim_options=sim_options)\n",
        "model.fit(trainSet)\n",
        "simsMatrix = model.compute_similarities()\n",
        "\n",
        "testUserInnerID = trainSet.to_inner_uid(testSubject)\n",
        "\n",
        "# Get the top K items we rated\n",
        "testUserRatings = trainSet.ur[testUserInnerID]\n",
        "kNeighbors = heapq.nlargest(k, testUserRatings, key=lambda t: t[1])\n",
        "\n",
        "# Get similar items to stuff we liked (weighted by rating)\n",
        "candidates = defaultdict(float)\n",
        "for itemID, rating in kNeighbors:\n",
        "    similarityRow = simsMatrix[itemID]\n",
        "    for innerID, score in enumerate(similarityRow):\n",
        "        candidates[innerID] += score * (rating / 5.0)\n",
        "    \n",
        "# Build a dictionary of stuff the user has already seen\n",
        "watched = {}\n",
        "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
        "    watched[itemID] = 1\n",
        "    \n",
        "# Get top-rated items from similar users:\n",
        "pos = 0\n",
        "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
        "    if not itemID in watched:\n",
        "        topicId = trainSet.to_raw_iid(itemID)\n",
        "        print(ml.gettopicName(int(topicId)), ratingSum)\n",
        "        pos += 1\n",
        "        if (pos > 10):\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "James Dean Story, The (1957) 10.0\n",
            "Get Real (1998) 9.987241120712646\n",
            "Kiss of Death (1995) 9.966881877751941\n",
            "Set It Off (1996) 9.963732215657119\n",
            "How Green Was My Valley (1941) 9.943984081065269\n",
            "Amos & Andrew (1993) 9.93973694500253\n",
            "My Crazy Life (Mi vida loca) (1993) 9.938290487546041\n",
            "Grace of My Heart (1996) 9.926255896645218\n",
            "Fanny and Alexander (Fanny och Alexander) (1982) 9.925699671455906\n",
            "Wild Reeds (Les roseaux sauvages) (1994) 9.916226404418774\n",
            "Edge of Seventeen (1998) 9.913028764691676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la3DMHlX7PK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7f0a16-3ef6-4d2f-d746-418c797c2a91"
      },
      "source": [
        "#from ExamLounge import ExamLounge\n",
        "from surprise import KNNBasic\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "        \n",
        "testSubject = '85'\n",
        "k = 10\n",
        "\n",
        "# Load our data set and compute the user similarity matrix\n",
        "ml = ExamLounge()\n",
        "data = ml.loadExamLoungeLatestSmall()\n",
        "\n",
        "trainSet = data.build_full_trainset()\n",
        "\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': True\n",
        "               }\n",
        "\n",
        "model = KNNBasic(sim_options=sim_options)\n",
        "model.fit(trainSet)\n",
        "simsMatrix = model.compute_similarities()\n",
        "\n",
        "# Get top N similar users to our test subject\n",
        "# (Alternate approach would be to select users up to some similarity threshold - try it!)\n",
        "testUserInnerID = trainSet.to_inner_uid(testSubject)\n",
        "similarityRow = simsMatrix[testUserInnerID]\n",
        "\n",
        "similarUsers = []\n",
        "for innerID, score in enumerate(similarityRow):\n",
        "    if (innerID != testUserInnerID):\n",
        "        similarUsers.append( (innerID, score) )\n",
        "\n",
        "kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])\n",
        "\n",
        "# Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
        "candidates = defaultdict(float)\n",
        "for similarUser in kNeighbors:\n",
        "    innerID = similarUser[0]\n",
        "    userSimilarityScore = similarUser[1]\n",
        "    theirRatings = trainSet.ur[innerID]\n",
        "    for rating in theirRatings:\n",
        "        candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
        "    \n",
        "# Build a dictionary of stuff the user has already seen\n",
        "watched = {}\n",
        "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
        "    watched[itemID] = 1\n",
        "    \n",
        "# Get top-rated items from similar users:\n",
        "pos = 0\n",
        "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
        "    if not itemID in watched:\n",
        "        topicId = trainSet.to_raw_iid(itemID)\n",
        "        print(ml.gettopicName(int(topicId)), ratingSum)\n",
        "        pos += 1\n",
        "        if (pos > 10):\n",
        "            break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Inception (2010) 3.3\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) 2.4\n",
            "Bourne Identity, The (1988) 2.0\n",
            "Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000) 2.0\n",
            "Dark Knight, The (2008) 2.0\n",
            "Good, the Bad and the Ugly, The (Buono, il brutto, il cattivo, Il) (1966) 1.9\n",
            "Departed, The (2006) 1.9\n",
            "Dark Knight Rises, The (2012) 1.9\n",
            "Back to the Future (1985) 1.9\n",
            "Gravity (2013) 1.8\n",
            "Fight Club (1999) 1.8\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}